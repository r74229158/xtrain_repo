{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac82aac2",
   "metadata": {},
   "source": [
    "Consider moving notebook to the main directory to avoid path errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Training.Trainer.BaseTrainer import BaseTrainer\n",
    "from Utils.configs import conf\n",
    "from Utils.model_utils import * \n",
    "from Training.Data.Modules.custom_loader import CustomLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbb4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = conf['simpleDNNTMnist']\n",
    "data_loader = CustomLoader(config[\"dataset\"], True, config[\"batch_size\"], shuffle_test=True)\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8613b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_model_activations(model, samples, labels):\n",
    "\n",
    "    labels = labels.long()\n",
    "    out_model = model(samples, apply_softmax=False)\n",
    "    best_score = out_model[torch.arange(out_model.shape[0]), labels]\n",
    "    \n",
    "    mask = torch.ones_like(out_model, dtype=torch.bool) \n",
    "    mask[torch.arange(out_model.shape[0]), labels] = False \n",
    "    other_scores = out_model[mask].reshape((out_model.shape[0], out_model.shape[1]-1))\n",
    "\n",
    "    gather_tensor = torch.zeros_like(out_model)\n",
    "    gather_tensor[:, 0] = best_score\n",
    "    gather_tensor[:, 1:] = other_scores\n",
    "\n",
    "    return gather_tensor.detach().cpu()\n",
    "\n",
    "def accuracy(Y_hat, Y, averaged=True):\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    \n",
    "    Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "    preds = Y_hat.argmax(axis=1).type(Y.dtype)\n",
    "    compare = (preds == Y.reshape(-1)).type(torch.float32)\n",
    "    return compare.mean() if averaged else compare\n",
    "\n",
    "def activation_evolution(activations_tracker):\n",
    "\n",
    "    cmap = plt.get_cmap(\"Oranges\")\n",
    "\n",
    "    shp = activations_tracker.shape[2]\n",
    "    colors = [cmap(0.3 + 0.5 * j / shp) for j in range(1, shp)]\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        sample_i = activations_tracker[:, i, :]\n",
    "\n",
    "        # BEST\n",
    "        plt.plot(np.arange(sample_i.shape[0]), \n",
    "                 sample_i[:, 0].numpy(), \n",
    "                 color='lightblue',\n",
    "                 linewidth=4,\n",
    "                 label=\"Target neuron\")\n",
    "        \n",
    "        plt.plot(np.arange(sample_i.shape[0]), \n",
    "                 torch.mean(sample_i[:, 1:], dim=1).numpy(), \n",
    "                 color=\"coral\", \n",
    "                 linewidth=4, \n",
    "                 label=\"Non-target neurons (mean)\"\n",
    "            )\n",
    "\n",
    "        lower = torch.min(sample_i[:, 1:], dim=1).values.numpy()\n",
    "        upper = torch.max(sample_i[:, 1:], dim=1).values.numpy()\n",
    "        plt.fill_between(\n",
    "            np.arange(sample_i.shape[0]), \n",
    "            lower, \n",
    "            upper, \n",
    "            color=colors[0], \n",
    "            alpha=0.2,  # Transparency (0=invisible, 1=opaque)\n",
    "            label=\"Non-target neurons (variation area)\"\n",
    "        )\n",
    "\n",
    "        for j in range(1, sample_i.shape[1]):\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Logits\")\n",
    "\n",
    "            plt.plot(np.arange(sample_i.shape[0]), \n",
    "                     sample_i[:, j].numpy(),\n",
    "                     color=colors[j-1], \n",
    "                     alpha=0.7,  # Slight transparency for lines\n",
    "                     linewidth=1.5\n",
    "            )\n",
    "        \n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Logits\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(os.getcwd() + f\"/Results/Experiments/01_logit_evolution/sample_{i}.pdf\", \n",
    "                    bbox_inches='tight', format='pdf')        \n",
    "        plt.close()\n",
    "\n",
    "def activation_evolution_statistics(activations_tracker, mean_acc):\n",
    "\n",
    "    next_activs = torch.zeros_like(activations_tracker)\n",
    "    for i in range(next_activs.shape[0]-1):\n",
    "        next_activs[i, :, :] = activations_tracker[i+1, :, :]\n",
    "    \n",
    "    activ_diff = next_activs - activations_tracker\n",
    "    activ_diff = activ_diff[:-1, :, :]\n",
    "\n",
    "    with open(os.getcwd() + \"/Results/Experiments/01_logit_evolution/logits_evolution.txt\", \"a+\") as f:\n",
    "\n",
    "        f.write(f\"Model Accuracy: {mean_acc} \\n\")\n",
    "        f.write(f'For all samples, the mean of best value changes as: {torch.mean(activ_diff[:, :, 0])} \\n')\n",
    "        f.write(f'For all samples, the mean of other values change as: {torch.mean(activ_diff[:, :, 1:])} \\n')\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTrainer(BaseTrainer):\n",
    "\n",
    "    def __init__(self, model, data, config, num_samples):\n",
    "\n",
    "        super().__init__(model, data, config, \"typeface_mnist\", num_samples)\n",
    "        \n",
    "        self.dev = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        os.makedirs(os.getcwd() + f\"/Results/Experiments/01_logit_evolution\", exist_ok=True)\n",
    "\n",
    "    def train(self):\n",
    "            \n",
    "        activ_changes = torch.zeros((self.epochs+1, self.X.shape[0], 10))\n",
    "        activ_changes[0, :, :] = track_model_activations(self.model, \n",
    "            self.X, self.labels).detach().cpu()\n",
    "        \n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            \n",
    "            train_bar = tqdm(enumerate(self.train_load), \n",
    "                        desc=f\"Epoch: {epoch}/{self.epochs}\",\n",
    "                        total=len(self.train_load)\n",
    "                    )\n",
    "            \n",
    "            self.model.train()\n",
    "            for batch in train_bar:\n",
    "                l = self.train_on_batch(batch[1])\n",
    "\n",
    "            self.scheduler.step()\n",
    "            activ_changes[epoch, :, :] = track_model_activations(self.model, \n",
    "                self.X, self.labels).detach().cpu()\n",
    "\n",
    "            self.model.eval()\n",
    "            metrics = np.zeros(len(self.test_load.dataset))\n",
    "            batch_size = 0\n",
    "\n",
    "            test_bar = tqdm(enumerate(self.test_load), \n",
    "                        desc=f\"Epoch: {epoch}/{self.epochs}\",\n",
    "                        total=len(self.test_load)\n",
    "                    )\n",
    "\n",
    "            for batch in test_bar:\n",
    "                l = self.validate_on_batch(batch[1])\n",
    "\n",
    "                bs = batch[1][0].size(0)\n",
    "                metrics[batch_size: batch_size+bs] = l.cpu().numpy()\n",
    "                batch_size += batch[1][0].size(0)\n",
    "\n",
    "            print(f\"Epoch {epoch}, Accuracy: {np.mean(metrics)}\")        \n",
    "            self.train_logs.append(np.mean(metrics))\n",
    "        \n",
    "        activation_evolution(activ_changes)\n",
    "        activation_evolution_statistics(activ_changes, np.mean(metrics))\n",
    "\n",
    "    def apply_loss(self, y_pred, y):\n",
    "\n",
    "        y_pred = y_pred.reshape((-1, y_pred.shape[-1]))\n",
    "        y = y.reshape((-1,))\n",
    "\n",
    "        if y[0].dtype == torch.int or torch.float32: y = y.long()\n",
    "\n",
    "        return self.loss(y_pred, y)\n",
    "\n",
    "    def train_on_batch(self, batch):\n",
    "\n",
    "        # Get data from batch, calculate loss and update\n",
    "        images, labels = batch[0], batch[1]\n",
    "        images = images.to(self.device); labels = labels.to(self.device)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        with autocast(device_type=self.dev):  # Enable mixed-precision\n",
    "\n",
    "            output = self.forward(images)\n",
    "            l = self.apply_loss(output, labels)\n",
    "\n",
    "        self.scaler.scale(l).backward()\n",
    "        self.scaler.step(self.optimizer)\n",
    "        self.scaler.update()\n",
    "        \n",
    "        return l\n",
    "\n",
    "    def validate_on_batch(self, batch):\n",
    "\n",
    "        images, labels = batch[0], batch[1]\n",
    "        images = images.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(images)\n",
    "\n",
    "        acc = accuracy(output, labels, averaged=False)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4336f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/theo-root/Documents/2_Projects/XTRAIN/Results/Datasets/typeface_mnist/run_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10: 100%|██████████| 374/374 [00:03<00:00, 120.07it/s]\n",
      "Epoch: 1/10: 100%|██████████| 94/94 [00:00<00:00, 128.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 0.27140468227424747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2/10: 100%|██████████| 374/374 [00:03<00:00, 118.81it/s]\n",
      "Epoch: 2/10: 100%|██████████| 94/94 [00:00<00:00, 130.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Accuracy: 0.43327759197324417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3/10: 100%|██████████| 374/374 [00:02<00:00, 125.40it/s]\n",
      "Epoch: 3/10: 100%|██████████| 94/94 [00:00<00:00, 126.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Accuracy: 0.3642140468227425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4/10: 100%|██████████| 374/374 [00:03<00:00, 124.59it/s]\n",
      "Epoch: 4/10: 100%|██████████| 94/94 [00:00<00:00, 128.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Accuracy: 0.5513377926421404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5/10: 100%|██████████| 374/374 [00:03<00:00, 116.02it/s]\n",
      "Epoch: 5/10: 100%|██████████| 94/94 [00:00<00:00, 129.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Accuracy: 0.5832775919732441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6/10: 100%|██████████| 374/374 [00:03<00:00, 121.51it/s]\n",
      "Epoch: 6/10: 100%|██████████| 94/94 [00:00<00:00, 117.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Accuracy: 0.5110367892976588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7/10: 100%|██████████| 374/374 [00:03<00:00, 121.01it/s]\n",
      "Epoch: 7/10: 100%|██████████| 94/94 [00:00<00:00, 125.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Accuracy: 0.6612040133779264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8/10: 100%|██████████| 374/374 [00:02<00:00, 125.41it/s]\n",
      "Epoch: 8/10: 100%|██████████| 94/94 [00:00<00:00, 128.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Accuracy: 0.7165551839464883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9/10: 100%|██████████| 374/374 [00:03<00:00, 123.42it/s]\n",
      "Epoch: 9/10: 100%|██████████| 94/94 [00:00<00:00, 126.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Accuracy: 0.7441471571906354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10/10: 100%|██████████| 374/374 [00:03<00:00, 112.17it/s]\n",
      "Epoch: 10/10: 100%|██████████| 94/94 [00:00<00:00, 122.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Accuracy: 0.7306020066889632\n"
     ]
    }
   ],
   "source": [
    "model = get_model_architecture(config['model_name'], config['model_layers'] + [config[\"num_classes\"]])\n",
    "trainer = SimpleTrainer(model, data_loader, config, num_samples)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81982f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model = get_model_architecture(config['model_name'], config['model_layers'] + [config[\"num_classes\"]])\n",
    "    trainer = SimpleTrainer(model, data_loader, config, num_samples)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dfd1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = conf['simpleDNNcorruptedMnist']\n",
    "data_loader = CustomLoader(config[\"dataset\"], True, config[\"batch_size\"], shuffle_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7595a5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(next(iter(data_loader.train_load))[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
