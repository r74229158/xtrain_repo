{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450a7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Training.Trainer.BaseTrainer import BaseTrainer\n",
    "from Utils.configs import conf\n",
    "from Utils.model_utils import * \n",
    "from Training.Data.Modules.custom_loader import CustomLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.getcwd() + f\"/Results/Experiments/01_logit_evolution\", exist_ok=True)\n",
    "config = conf['simpleDNNTMnist']\n",
    "\n",
    "data_loader = CustomLoader(config[\"dataset\"], True, config[\"batch_size\"], shuffle_test=True)\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8613b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_model_activations(model, samples, labels):\n",
    "\n",
    "    labels = labels.long()\n",
    "    out_model = model(samples, apply_softmax=False)\n",
    "    best_score = out_model[torch.arange(out_model.shape[0]), labels]\n",
    "    \n",
    "    mask = torch.ones_like(out_model, dtype=torch.bool) \n",
    "    mask[torch.arange(out_model.shape[0]), labels] = False \n",
    "    other_scores = out_model[mask].reshape((out_model.shape[0], out_model.shape[1]-1))\n",
    "\n",
    "    gather_tensor = torch.zeros_like(out_model)\n",
    "    gather_tensor[:, 0] = best_score\n",
    "    gather_tensor[:, 1:] = other_scores\n",
    "\n",
    "    return gather_tensor.detach().cpu()\n",
    "\n",
    "def accuracy(Y_hat, Y, averaged=True):\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    \n",
    "    Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "    preds = Y_hat.argmax(axis=1).type(Y.dtype)\n",
    "    compare = (preds == Y.reshape(-1)).type(torch.float32)\n",
    "    return compare.mean() if averaged else compare\n",
    "\n",
    "def activation_evolution(activations_tracker):\n",
    "\n",
    "    cmap = plt.get_cmap(\"Oranges\")\n",
    "\n",
    "    shp = activations_tracker.shape[2]\n",
    "    colors = [cmap(0.3 + 0.5 * j / shp) for j in range(1, shp)]\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        sample_i = activations_tracker[:, i, :]\n",
    "\n",
    "        # BEST\n",
    "        plt.plot(np.arange(sample_i.shape[0]), \n",
    "                 sample_i[:, 0].numpy(), \n",
    "                 color='lightblue',\n",
    "                 linewidth=4,\n",
    "                 label=\"Target neuron\")\n",
    "        \n",
    "        plt.plot(np.arange(sample_i.shape[0]), \n",
    "                 torch.mean(sample_i[:, 1:], dim=1).numpy(), \n",
    "                 color=\"coral\", \n",
    "                 linewidth=4, \n",
    "                 label=\"Non-target neurons (mean)\"\n",
    "            )\n",
    "\n",
    "        lower = torch.min(sample_i[:, 1:], dim=1).values.numpy()\n",
    "        upper = torch.max(sample_i[:, 1:], dim=1).values.numpy()\n",
    "        plt.fill_between(\n",
    "            np.arange(sample_i.shape[0]), \n",
    "            lower, \n",
    "            upper, \n",
    "            color=colors[0], \n",
    "            alpha=0.2,  # Transparency (0=invisible, 1=opaque)\n",
    "            label=\"Non-target neurons (variation area)\"\n",
    "        )\n",
    "\n",
    "        for j in range(1, sample_i.shape[1]):\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Logits\")\n",
    "\n",
    "            plt.plot(np.arange(sample_i.shape[0]), \n",
    "                     sample_i[:, j].numpy(),\n",
    "                     color=colors[j-1], \n",
    "                     alpha=0.7,  # Slight transparency for lines\n",
    "                     linewidth=1.5\n",
    "            )\n",
    "        \n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Logits\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(os.getcwd() + f\"/Results/Experiments/01_logit_evolution/sample_{i}.pdf\", \n",
    "                    bbox_inches='tight', format='pdf')        \n",
    "        plt.close()\n",
    "\n",
    "def activation_evolution_statistics(activations_tracker, mean_acc):\n",
    "\n",
    "    next_activs = torch.zeros_like(activations_tracker)\n",
    "    for i in range(next_activs.shape[0]-1):\n",
    "        next_activs[i, :, :] = activations_tracker[i+1, :, :]\n",
    "    \n",
    "    activ_diff = next_activs - activations_tracker\n",
    "    activ_diff = activ_diff[:-1, :, :]\n",
    "\n",
    "    with open(os.getcwd() + \"/Results/Experiments/01_logit_evolution/logits_evolution.txt\", \"a+\") as f:\n",
    "\n",
    "        f.write(f\"Model Accuracy: {mean_acc} \\n\")\n",
    "        f.write(f'For all samples, the mean of best value changes as: {torch.mean(activ_diff[:, :, 0])} \\n')\n",
    "        f.write(f'For all samples, the mean of other values change as: {torch.mean(activ_diff[:, :, 1:])} \\n')\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTrainer(BaseTrainer):\n",
    "\n",
    "    def __init__(self, model, data, config, num_samples):\n",
    "\n",
    "        super().__init__(model, config, data, num_samples, save_results=False)\n",
    "        \n",
    "        self.dev = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self):\n",
    "            \n",
    "        activ_changes = torch.zeros((self.epochs+1, self.X.shape[0], 10))\n",
    "        activ_changes[0, :, :] = track_model_activations(self.model, \n",
    "            self.X, self.labels).detach().cpu()\n",
    "        \n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            \n",
    "            train_bar = tqdm(enumerate(self.train_load), \n",
    "                        desc=f\"Epoch: {epoch}/{self.epochs}\",\n",
    "                        total=len(self.train_load)\n",
    "                    )\n",
    "            \n",
    "            self.model.train()\n",
    "            for batch in train_bar:\n",
    "                l = self.train_on_batch(batch[1])\n",
    "\n",
    "            self.scheduler.step()\n",
    "            activ_changes[epoch, :, :] = track_model_activations(self.model, \n",
    "                self.X, self.labels).detach().cpu()\n",
    "\n",
    "            self.model.eval()\n",
    "            metrics = np.zeros(len(self.test_load.dataset))\n",
    "            batch_size = 0\n",
    "\n",
    "            test_bar = tqdm(enumerate(self.test_load), \n",
    "                        desc=f\"Epoch: {epoch}/{self.epochs}\",\n",
    "                        total=len(self.test_load)\n",
    "                    )\n",
    "\n",
    "            for batch in test_bar:\n",
    "                l = self.validate_on_batch(batch[1])\n",
    "\n",
    "                bs = batch[1][0].size(0)\n",
    "                metrics[batch_size: batch_size+bs] = l.cpu().numpy()\n",
    "                batch_size += batch[1][0].size(0)\n",
    "\n",
    "            print(f\"Epoch {epoch}, Accuracy: {np.mean(metrics)}\")        \n",
    "            self.train_logs.append(np.mean(metrics))\n",
    "        \n",
    "        # activation_evolution(activ_changes)\n",
    "        activation_evolution_statistics(activ_changes, np.mean(metrics))\n",
    "\n",
    "    def apply_loss(self, y_pred, y):\n",
    "\n",
    "        y_pred = y_pred.reshape((-1, y_pred.shape[-1]))\n",
    "        y = y.reshape((-1,))\n",
    "\n",
    "        if y[0].dtype == torch.int or torch.float32: y = y.long()\n",
    "\n",
    "        return self.loss(y_pred, y)\n",
    "\n",
    "    def train_on_batch(self, batch):\n",
    "\n",
    "        # Get data from batch, calculate loss and update\n",
    "        images, labels = batch[0], batch[1]\n",
    "        images = images.to(self.device); labels = labels.to(self.device)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        with autocast(device_type=self.dev):  # Enable mixed-precision\n",
    "\n",
    "            output = self.forward(images)\n",
    "            l = self.apply_loss(output, labels)\n",
    "\n",
    "        self.scaler.scale(l).backward()\n",
    "        self.scaler.step(self.optimizer)\n",
    "        self.scaler.update()\n",
    "        \n",
    "        return l\n",
    "\n",
    "    def validate_on_batch(self, batch):\n",
    "\n",
    "        images, labels = batch[0], batch[1]\n",
    "        images = images.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(images)\n",
    "\n",
    "        acc = accuracy(output, labels, averaged=False)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81982f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = config['model_layers']\n",
    "# layers = [784, 512, 256, 64, 10]\n",
    "\n",
    "for i in range(10):\n",
    "    model = get_model_architecture(config['model_name'], layers + [config[\"num_classes\"]])\n",
    "    trainer = SimpleTrainer(model, data_loader, config, num_samples)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88f2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.getcwd() + \"/Results/Experiments/01_logit_evolution/logits_evolution.txt\"\n",
    "with open(file, 'r') as f:\n",
    "    \n",
    "    lines = [l for l in f.readlines()]\n",
    "\n",
    "    acc_scores = [float(l.rsplit(\":\")[1][1:-2]) for l in lines if \"Model Accuracy\" in l]\n",
    "    targ_values = [float(l.rsplit(\":\")[1][1:-2]) for l in lines if \"best value\" in l]\n",
    "    notarg_values = [float(l.rsplit(\":\")[1][1:-2]) for l in lines if \"other values\" in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff9bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:  0.8831605351170568\n",
      "STD Accuracy:  0.053661651794216995\n",
      "Mean Logit Target Update:  0.653751540184021\n",
      "STD Logit Target Update:  0.03661135019573068\n",
      "Mean Logit Non-Target Update:  -0.06500565763562918\n",
      "STD Logit Non-Target Update:  0.029020444148339045\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy: \", np.mean(acc_scores))\n",
    "print(\"STD Accuracy: \", np.std(acc_scores, ddof=1))\n",
    "print(\"Mean Logit Target Update: \", np.mean(targ_values))\n",
    "print(\"STD Logit Target Update: \", np.std(targ_values, ddof=1))\n",
    "print(\"Mean Logit Non-Target Update: \", np.mean(notarg_values))\n",
    "print(\"STD Logit Non-Target Update: \", np.std(notarg_values, ddof=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
